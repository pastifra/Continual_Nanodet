{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T16:23:29.226237478Z",
     "start_time": "2024-02-19T16:23:27.721982515Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "import yaml\n",
    "import sys\n",
    "sys.path.append('/home/pasti/PycharmProjects/Continual_Nanodet/')\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import numpy as np\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "from pytorch_lightning.accelerators import find_usable_cuda_devices\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nanodet.data.collate import naive_collate\n",
    "from nanodet.data.dataset import build_dataset\n",
    "from nanodet.evaluator import build_evaluator\n",
    "from nanodet.trainer.task import TrainingTask\n",
    "from nanodet.trainer.pseudo_lab_task import PseudoLabelTrainingTask\n",
    "from nanodet.trainer.dist_task import DistTrainingTask\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from nanodet.util import (\n",
    "    NanoDetLightningLogger,\n",
    "    cfg,\n",
    "    convert_old_model,\n",
    "    env_utils,\n",
    "    load_config,\n",
    "    load_model_weight,\n",
    "    mkdir,\n",
    ")\n",
    "\n",
    "#Set logger and seed\n",
    "logger = NanoDetLightningLogger('test')\n",
    "pl.seed_everything(9)\n",
    "\n",
    "#Function to create the task configuration file required for training\n",
    "def create_exp_cfg(yml_path, task):\n",
    "    all_names = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "    #Load the YAML file\n",
    "    with open(yml_path, 'r') as file:\n",
    "        temp_cfg = yaml.safe_load(file)\n",
    "    #Save dir of the model\n",
    "    temp_cfg['save_dir'] = 'models/task' + str(task)\n",
    "    #If base task, training and testing classes are the same\n",
    "    if task == 0:\n",
    "        temp_cfg['data']['train']['class_names'] = all_names[:15]\n",
    "        temp_cfg['data']['val']['class_names'] = all_names[:15]\n",
    "        temp_cfg['model']['arch']['head']['num_classes'] = 20 #15\n",
    "        #temp_cfg['model']['arch']['aux_head']['num_classes'] = 20 #15\n",
    "    #Else, training only on task specific class, and testing on all classes\n",
    "    else:\n",
    "        temp_cfg['data']['train']['class_names'] = [all_names[14+task]]\n",
    "        temp_cfg['data']['val']['class_names'] = all_names[:15+task]\n",
    "        temp_cfg['model']['arch']['head']['num_classes'] = 20#15+task\n",
    "        #temp_cfg['model']['arch']['aux_head']['num_classes'] = 20#15+task\n",
    "        temp_cfg['schedule']['load_model'] = 'models/task' + str(task-1) + '/model_last.ckpt'\n",
    "        \n",
    "    temp_cfg_name = 'cfg/task' + str(task) + '.yml'\n",
    "    print(temp_cfg_name)\n",
    "    #Save the new configuration file\n",
    "    with open(temp_cfg_name, 'w') as file:\n",
    "        yaml.safe_dump(temp_cfg, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T16:23:36.331323677Z",
     "start_time": "2024-02-19T16:23:30.333719337Z"
    }
   },
   "outputs": [],
   "source": [
    "###LEARNING STREAM###\n",
    "#task 0: train on first 15 classes, test on 15 classes\n",
    "#task 1: train on class n°16, test on 16 classes\n",
    "#task 2: train on class n°17, test on 17 classes\n",
    "#task 3: train on class n°18, test on 18 classes\n",
    "#task 4: train on class n°19, test on 19 classes\n",
    "#task 5: train on class n°20, test on 20 classes\n",
    "#torch.set_printoptions(profile=\"full\")\n",
    "#opt_epochs = [60, 80, 40, 60 ,40]\n",
    "for task in range (1, 6):\n",
    "    logger = NanoDetLightningLogger('run_logs/task'+str(task))\n",
    "    logger.info(\"Starting task\" + str(task))\n",
    "    logger.info(\"Setting up data...\")\n",
    "    #Create the task configuration file based on the task number and load the configuration\n",
    "    create_exp_cfg('cfg/VOC.yml', task)\n",
    "    load_config(cfg, 'cfg/task' + str(task) + '.yml')\n",
    "    #Build datasets and dataloaders based on the task configuration file\n",
    "    train_dataset = build_dataset(cfg.data.train, \"train\")\n",
    "    #If task is not 0, create the replay dataset using the buffer\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=cfg.device.batchsize_per_gpu,\n",
    "        shuffle=True,\n",
    "        num_workers=cfg.device.workers_per_gpu,\n",
    "        pin_memory=True,\n",
    "        collate_fn=naive_collate,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    val_dataset = build_dataset(cfg.data.val, \"test\")\n",
    "    val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=cfg.device.batchsize_per_gpu,\n",
    "        shuffle=False,\n",
    "        num_workers=cfg.device.workers_per_gpu,\n",
    "        pin_memory=True,\n",
    "        collate_fn=naive_collate,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    evaluator = build_evaluator(cfg.evaluator, val_dataset)\n",
    "    \n",
    "    #Create the model based on the task configuration file\n",
    "    logger.info(\"Creating models\")\n",
    "    if task == 0:\n",
    "        TrainTask = TrainingTask(cfg, evaluator)\n",
    "    else:\n",
    "        TrainTask = PseudoLabelTrainingTask(cfg, evaluator)\n",
    "        #Load the model weights if task is not 0\n",
    "        if \"load_model\" in cfg.schedule:\n",
    "            ckpt = torch.load(cfg.schedule.load_model)\n",
    "            load_model_weight(TrainTask.model, ckpt, logger)\n",
    "            logger.info(\"Loaded model weight from {}\".format(cfg.schedule.load_model))\n",
    "    \n",
    "    model_resume_path = (\n",
    "        os.path.join(cfg.save_dir, \"model_last.ckpt\")\n",
    "        if \"resume\" in cfg.schedule\n",
    "        else None\n",
    "    )\n",
    "    #Set the device to GPU if available\n",
    "    if cfg.device.gpu_ids == -1:\n",
    "        logger.info(\"Using CPU training\")\n",
    "        accelerator, devices, strategy, precision = (\n",
    "            \"cpu\",\n",
    "            None,\n",
    "            None,\n",
    "            cfg.device.precision,\n",
    "        )\n",
    "    else:\n",
    "        accelerator, devices, strategy, precision = (\n",
    "            \"gpu\",\n",
    "            cfg.device.gpu_ids,\n",
    "            None,\n",
    "            cfg.device.precision,\n",
    "        )\n",
    "\n",
    "    if devices and len(devices) > 1:\n",
    "        strategy = \"ddp\"\n",
    "        env_utils.set_multi_processing(distributed=True)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        default_root_dir=cfg.save_dir,\n",
    "        max_epochs=100,\n",
    "        check_val_every_n_epoch=10,\n",
    "        accelerator=accelerator,\n",
    "        devices=[2],\n",
    "        log_every_n_steps=cfg.log.interval,\n",
    "        num_sanity_val_steps=0,\n",
    "        callbacks=[TQDMProgressBar(refresh_rate=0)],# TrainTask.early_stop_callback],\n",
    "        logger=logger,\n",
    "        benchmark=cfg.get(\"cudnn_benchmark\", True),\n",
    "        gradient_clip_val=cfg.get(\"grad_clip\", 0.0),\n",
    "        strategy=strategy,\n",
    "        precision=precision,\n",
    "    )\n",
    "    trainer.fit(TrainTask, train_dataloader, val_dataloader, ckpt_path=model_resume_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## DEBUGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T16:09:07.269648749Z",
     "start_time": "2024-02-19T16:09:06.424887298Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "task = 0\n",
    "logger = NanoDetLightningLogger('run_logs/task'+str(task))\n",
    "logger.info(\"Starting task\" + str(task))\n",
    "logger.info(\"Setting up data...\")\n",
    "#Create the task configuration file based on the task number and load the configuration\n",
    "create_exp_cfg('cfg/VOC.yml', task)\n",
    "load_config(cfg, 'cfg/task' + str(task) + '.yml')\n",
    "#Build datasets and dataloaders based on the task configuration file\n",
    "train_dataset = build_dataset(cfg.data.train, \"train\")\n",
    "#If task is not 0, create the replay dataset using the buffer\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=cfg.device.workers_per_gpu,\n",
    "    pin_memory=True,\n",
    "    collate_fn=naive_collate,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_dataset = build_dataset(cfg.data.val, \"test\")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=cfg.device.workers_per_gpu,\n",
    "    pin_memory=True,\n",
    "    collate_fn=naive_collate,\n",
    "    drop_last=False,\n",
    ")\n",
    "evaluator = build_evaluator(cfg.evaluator, val_dataset)\n",
    "\n",
    "#Create the model based on the task configuration file\n",
    "logger.info(\"Creating models\")\n",
    "if task == 0:\n",
    "    TrainTask = TrainingTask(cfg, evaluator)\n",
    "else:\n",
    "    TrainTask = DistTrainingTask(cfg, evaluator)\n",
    "    #Load the model weights if task is not 0\n",
    "    if \"load_model\" in cfg.schedule:\n",
    "        ckpt = torch.load(cfg.schedule.load_model)\n",
    "        load_model_weight(TrainTask.model, ckpt, logger)\n",
    "        load_model_weight(TrainTask.teacher, ckpt, logger)\n",
    "        logger.info(\"Loaded model weight from {}\".format(cfg.schedule.load_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T16:21:57.926479736Z",
     "start_time": "2024-02-19T16:21:55.987373031Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in train_dataloader:\n",
    "    print(batch['img_info']['id'])\n",
    "    if i == 2:\n",
    "        break\n",
    "    batch = batch\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T16:20:10.241873147Z",
     "start_time": "2024-02-19T16:20:10.203916580Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_boxes = batch[\"gt_bboxes\"]\n",
    "print(gt_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T16:22:03.722327462Z",
     "start_time": "2024-02-19T16:22:02.755868811Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = batch[\"img\"]\n",
    "print(img)\n",
    "stud_feat = TrainTask.model.backbone(img)\n",
    "stud_fpn_feat = TrainTask.model.fpn(stud_feat)\n",
    "head_out = TrainTask.model.head(stud_fpn_feat)\n",
    "dets = TrainTask.model.head.post_process(head_out, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T16:22:35.413800569Z",
     "start_time": "2024-02-19T16:22:35.402152342Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "id = 0\n",
    "for img_id, img_dets in dets.items():\n",
    "    boxes = []\n",
    "    labels = []\n",
    "    for label, bboxes in img_dets.items():\n",
    "        for bbox in bboxes:\n",
    "            score = bbox[-1]\n",
    "            if score > 0.3:\n",
    "                x0, y0, x1, y1 = [int(i) for i in bbox[:4]]\n",
    "                boxes.append([x0, y0, x1, y1])\n",
    "                labels.append(label)\n",
    "    \n",
    "    batch[\"gt_bboxes\"][id] = np.append(batch[\"gt_bboxes\"][id],np.array(boxes,dtype=np.float32))\n",
    "    batch[\"gt_labels\"][id] = np.append(batch[\"gt_labels\"][id],np.array(labels))\n",
    "    id += 1\n",
    "print(len(batch[\"gt_bboxes\"]))\n",
    "        #batch[\"gt_bboxes\"].extend(np.array(all_box, dtype=np.float32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanodet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
