{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T08:56:29.818146924Z",
     "start_time": "2024-02-21T08:56:28.258161981Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 9\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "import yaml\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "from pytorch_lightning.accelerators import find_usable_cuda_devices\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nanodet.data.collate import naive_collate\n",
    "from nanodet.data.dataset import build_dataset\n",
    "from nanodet.evaluator import build_evaluator\n",
    "from nanodet.trainer.task import TrainingTask\n",
    "from nanodet.trainer.latent_dist_task import LatentDistTrainingTask\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from nanodet.util import (\n",
    "    NanoDetLightningLogger,\n",
    "    cfg,\n",
    "    convert_old_model,\n",
    "    env_utils,\n",
    "    load_config,\n",
    "    load_model_weight,\n",
    "    mkdir,\n",
    ")\n",
    "\n",
    "#Set logger and seed\n",
    "logger = NanoDetLightningLogger('test')\n",
    "pl.seed_everything(9)\n",
    "\n",
    "#Function to create the task configuration file required for training\n",
    "def create_exp_cfg(yml_path, task):\n",
    "    all_names = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "    #Load the YAML file\n",
    "    with open(yml_path, 'r') as file:\n",
    "        temp_cfg = yaml.safe_load(file)\n",
    "    #Save dir of the model\n",
    "    temp_cfg['save_dir'] = 'models/task' + str(task)\n",
    "    #If base task, training and testing classes are the same\n",
    "    if task == 0:\n",
    "        temp_cfg['data']['train']['class_names'] = all_names[:15]\n",
    "        temp_cfg['data']['val']['class_names'] = all_names[:15]\n",
    "        temp_cfg['model']['arch']['head']['num_classes'] = 20 #15\n",
    "        #temp_cfg['model']['arch']['aux_head']['num_classes'] = 20 #15\n",
    "    #Else, training only on task specific class, and testing on all classes\n",
    "    else:\n",
    "        temp_cfg['data']['train']['class_names'] = [all_names[14+task]]\n",
    "        temp_cfg['data']['val']['class_names'] = all_names[:15+task]\n",
    "        temp_cfg['model']['arch']['head']['num_classes'] = 20#15+task\n",
    "        #temp_cfg['model']['arch']['aux_head']['num_classes'] = 20#15+task\n",
    "        temp_cfg['schedule']['load_model'] = 'models/task' + str(task-1) + '/model_last.ckpt'\n",
    "        \n",
    "    temp_cfg_name = 'cfg/task' + str(task) + '.yml'\n",
    "    print(temp_cfg_name)\n",
    "    #Save the new configuration file\n",
    "    with open(temp_cfg_name, 'w') as file:\n",
    "        yaml.safe_dump(temp_cfg, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T08:58:28.597188161Z",
     "start_time": "2024-02-21T08:58:27.592250321Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-21 09:58:27]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mStarting task5\u001B[0m\n",
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-21 09:58:27]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mStarting task5\u001B[0m\n",
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-21 09:58:27]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mStarting task5\u001B[0m\n",
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-21 09:58:27]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mSetting up data...\u001B[0m\n",
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-21 09:58:27]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mSetting up data...\u001B[0m\n",
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-21 09:58:27]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mSetting up data...\u001B[0m\n",
      "WARNING:root:WARNING! Keeping only annotations of these categories [{'supercategory': 'tvmonitor', 'id': 20, 'name': 'tvmonitor'}]! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg/task5.yml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:WARNING! Keeping only annotations of these categories [{'supercategory': 'aeroplane', 'id': 1, 'name': 'aeroplane'}, {'supercategory': 'bicycle', 'id': 2, 'name': 'bicycle'}, {'supercategory': 'bird', 'id': 3, 'name': 'bird'}, {'supercategory': 'boat', 'id': 4, 'name': 'boat'}, {'supercategory': 'bottle', 'id': 5, 'name': 'bottle'}, {'supercategory': 'bus', 'id': 6, 'name': 'bus'}, {'supercategory': 'car', 'id': 7, 'name': 'car'}, {'supercategory': 'cat', 'id': 8, 'name': 'cat'}, {'supercategory': 'chair', 'id': 9, 'name': 'chair'}, {'supercategory': 'cow', 'id': 10, 'name': 'cow'}, {'supercategory': 'diningtable', 'id': 11, 'name': 'diningtable'}, {'supercategory': 'dog', 'id': 12, 'name': 'dog'}, {'supercategory': 'horse', 'id': 13, 'name': 'horse'}, {'supercategory': 'motorbike', 'id': 14, 'name': 'motorbike'}, {'supercategory': 'person', 'id': 15, 'name': 'person'}, {'supercategory': 'pottedplant', 'id': 16, 'name': 'pottedplant'}, {'supercategory': 'sheep', 'id': 17, 'name': 'sheep'}, {'supercategory': 'sofa', 'id': 18, 'name': 'sofa'}, {'supercategory': 'train', 'id': 19, 'name': 'train'}, {'supercategory': 'tvmonitor', 'id': 20, 'name': 'tvmonitor'}]! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 279 xml files and 367 boxes\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-21 09:58:28]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mCreating models\u001B[0m\n",
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-21 09:58:28]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mCreating models\u001B[0m\n",
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-21 09:58:28]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mCreating models\u001B[0m\n",
      "INFO:NanoDet:Creating models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 4952 xml files and 14976 boxes\n",
      "creating index...\n",
      "index created!\n",
      "model size is  1.0x\n",
      "init weights...\n",
      "=> loading pretrained model https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth\n",
      "Finish initialize NanoDet-Plus Head.\n",
      "model size is  1.0x\n",
      "init weights...\n",
      "=> loading pretrained model https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth\n",
      "Finish initialize NanoDet-Plus Head.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/task4/model_last.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 49\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;66;03m#Load the model weights if task is not 0\u001B[39;00m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mload_model\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m cfg\u001B[38;5;241m.\u001B[39mschedule:\n\u001B[0;32m---> 49\u001B[0m     ckpt \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcfg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mschedule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m     load_model_weight(TrainTask\u001B[38;5;241m.\u001B[39mmodel, ckpt, logger)\n\u001B[1;32m     51\u001B[0m     load_model_weight(TrainTask\u001B[38;5;241m.\u001B[39mteacher, ckpt, logger)\n",
      "File \u001B[0;32m~/anaconda3/envs/nanodet/lib/python3.10/site-packages/torch/serialization.py:771\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001B[0m\n\u001B[1;32m    768\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    769\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 771\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[1;32m    772\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[1;32m    773\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[1;32m    774\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[1;32m    775\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[1;32m    776\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[0;32m~/anaconda3/envs/nanodet/lib/python3.10/site-packages/torch/serialization.py:270\u001B[0m, in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    268\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[1;32m    269\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[0;32m--> 270\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    271\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    272\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[0;32m~/anaconda3/envs/nanodet/lib/python3.10/site-packages/torch/serialization.py:251\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[0;32m--> 251\u001B[0m     \u001B[38;5;28msuper\u001B[39m(_open_file, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'models/task4/model_last.ckpt'"
     ]
    }
   ],
   "source": [
    "###LEARNING STREAM###\n",
    "#task 0: train on first 15 classes, test on 15 classes\n",
    "#task 1: train on class n°16, test on 16 classes\n",
    "#task 2: train on class n°17, test on 17 classes\n",
    "#task 3: train on class n°18, test on 18 classes\n",
    "#task 4: train on class n°19, test on 19 classes\n",
    "#task 5: train on class n°20, test on 20 classes\n",
    "#torch.set_printoptions(profile=\"full\")\n",
    "#opt_epochs = [60, 80, 40, 60 ,40]\n",
    "for task in range (5, 6):\n",
    "    logger = NanoDetLightningLogger('run_logs/task'+str(task))\n",
    "    logger.info(\"Starting task\" + str(task))\n",
    "    logger.info(\"Setting up data...\")\n",
    "    #Create the task configuration file based on the task number and load the configuration\n",
    "    create_exp_cfg('cfg/VOC_dist1.yml', task)\n",
    "    load_config(cfg, 'cfg/task' + str(task) + '.yml')\n",
    "    #Build datasets and dataloaders based on the task configuration file\n",
    "    train_dataset = build_dataset(cfg.data.train, \"train\")\n",
    "    #If task is not 0, create the replay dataset using the buffer\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=cfg.device.batchsize_per_gpu,\n",
    "        shuffle=True,\n",
    "        num_workers=cfg.device.workers_per_gpu,\n",
    "        pin_memory=True,\n",
    "        collate_fn=naive_collate,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    val_dataset = build_dataset(cfg.data.val, \"test\")\n",
    "    val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=cfg.device.batchsize_per_gpu,\n",
    "        shuffle=False,\n",
    "        num_workers=cfg.device.workers_per_gpu,\n",
    "        pin_memory=True,\n",
    "        collate_fn=naive_collate,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    evaluator = build_evaluator(cfg.evaluator, val_dataset)\n",
    "    \n",
    "    #Create the model based on the task configuration file\n",
    "    logger.info(\"Creating models\")\n",
    "    if task == 0:\n",
    "        TrainTask = TrainingTask(cfg, evaluator)\n",
    "    else:\n",
    "        TrainTask = LatentDistTrainingTask(cfg, evaluator)\n",
    "        #Load the model weights if task is not 0\n",
    "        if \"load_model\" in cfg.schedule:\n",
    "            ckpt = torch.load(cfg.schedule.load_model)\n",
    "            load_model_weight(TrainTask.model, ckpt, logger)\n",
    "            load_model_weight(TrainTask.teacher, ckpt, logger)\n",
    "            logger.info(\"Loaded model weight from {}\".format(cfg.schedule.load_model))\n",
    "    \n",
    "    model_resume_path = (\n",
    "        os.path.join(cfg.save_dir, \"model_last.ckpt\")\n",
    "        if \"resume\" in cfg.schedule\n",
    "        else None\n",
    "    )\n",
    "    #Set the device to GPU if available\n",
    "    if cfg.device.gpu_ids == -1:\n",
    "        logger.info(\"Using CPU training\")\n",
    "        accelerator, devices, strategy, precision = (\n",
    "            \"cpu\",\n",
    "            None,\n",
    "            None,\n",
    "            cfg.device.precision,\n",
    "        )\n",
    "    else:\n",
    "        accelerator, devices, strategy, precision = (\n",
    "            \"gpu\",\n",
    "            cfg.device.gpu_ids,\n",
    "            None,\n",
    "            cfg.device.precision,\n",
    "        )\n",
    "\n",
    "    if devices and len(devices) > 1:\n",
    "        strategy = \"ddp\"\n",
    "        env_utils.set_multi_processing(distributed=True)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        default_root_dir=cfg.save_dir,\n",
    "        max_epochs=100,\n",
    "        check_val_every_n_epoch=10,\n",
    "        accelerator=accelerator,\n",
    "        devices=[2],\n",
    "        log_every_n_steps=cfg.log.interval,\n",
    "        num_sanity_val_steps=0,\n",
    "        callbacks=[TQDMProgressBar(refresh_rate=0)],# TrainTask.early_stop_callback],\n",
    "        logger=logger,\n",
    "        benchmark=cfg.get(\"cudnn_benchmark\", True),\n",
    "        gradient_clip_val=cfg.get(\"grad_clip\", 0.0),\n",
    "        strategy=strategy,\n",
    "        precision=precision,\n",
    "    )\n",
    "    trainer.fit(TrainTask, train_dataloader, val_dataloader, ckpt_path=model_resume_path)\n",
    "    state_dict = TrainTask.model.state_dict()\n",
    "    new_state_dict = {k: v for k, v in state_dict.items() if \"teacher\" not in k}\n",
    "    \n",
    "    torch.save({'state_dict': new_state_dict}, 'models/task' + str(task) + '/model_last.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-20 15:03:17]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mStarting task1\u001B[0m\n",
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-20 15:03:17]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mStarting task1\u001B[0m\n",
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-20 15:03:17]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mStarting task1\u001B[0m\n",
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-20 15:03:17]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mStarting task1\u001B[0m\n",
      "INFO:NanoDet:Starting task1\n",
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-20 15:03:17]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mSetting up data...\u001B[0m\n",
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-20 15:03:17]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mSetting up data...\u001B[0m\n",
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-20 15:03:17]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mSetting up data...\u001B[0m\n",
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-20 15:03:17]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mSetting up data...\u001B[0m\n",
      "INFO:NanoDet:Setting up data...\n",
      "WARNING:root:WARNING! Keeping only annotations of these categories [{'supercategory': 'pottedplant', 'id': 16, 'name': 'pottedplant'}]! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg/task1.yml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:WARNING! Keeping only annotations of these categories [{'supercategory': 'aeroplane', 'id': 1, 'name': 'aeroplane'}, {'supercategory': 'bicycle', 'id': 2, 'name': 'bicycle'}, {'supercategory': 'bird', 'id': 3, 'name': 'bird'}, {'supercategory': 'boat', 'id': 4, 'name': 'boat'}, {'supercategory': 'bottle', 'id': 5, 'name': 'bottle'}, {'supercategory': 'bus', 'id': 6, 'name': 'bus'}, {'supercategory': 'car', 'id': 7, 'name': 'car'}, {'supercategory': 'cat', 'id': 8, 'name': 'cat'}, {'supercategory': 'chair', 'id': 9, 'name': 'chair'}, {'supercategory': 'cow', 'id': 10, 'name': 'cow'}, {'supercategory': 'diningtable', 'id': 11, 'name': 'diningtable'}, {'supercategory': 'dog', 'id': 12, 'name': 'dog'}, {'supercategory': 'horse', 'id': 13, 'name': 'horse'}, {'supercategory': 'motorbike', 'id': 14, 'name': 'motorbike'}, {'supercategory': 'person', 'id': 15, 'name': 'person'}, {'supercategory': 'pottedplant', 'id': 16, 'name': 'pottedplant'}]! \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 273 xml files and 625 boxes\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-20 15:03:18]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mCreating models\u001B[0m\n",
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-20 15:03:18]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mCreating models\u001B[0m\n",
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-20 15:03:18]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mCreating models\u001B[0m\n",
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-20 15:03:18]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mCreating models\u001B[0m\n",
      "INFO:NanoDet:Creating models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 4530 xml files and 13606 boxes\n",
      "creating index...\n",
      "index created!\n",
      "model size is  1.0x\n",
      "init weights...\n",
      "=> loading pretrained model https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth\n",
      "Finish initialize NanoDet-Plus Head.\n",
      "model size is  1.0x\n",
      "init weights...\n",
      "=> loading pretrained model https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth\n",
      "Finish initialize NanoDet-Plus Head.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-20 15:03:18]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mLoaded model weight from models/task0/model_last.ckpt\u001B[0m\n",
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-20 15:03:18]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mLoaded model weight from models/task0/model_last.ckpt\u001B[0m\n",
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-20 15:03:18]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mLoaded model weight from models/task0/model_last.ckpt\u001B[0m\n",
      "\u001B[1m\u001B[35m[NanoDet]\u001B[0m\u001B[34m[02-20 15:03:18]\u001B[0m\u001B[32mINFO:\u001B[0m\u001B[97mLoaded model weight from models/task0/model_last.ckpt\u001B[0m\n",
      "INFO:NanoDet:Loaded model weight from models/task0/model_last.ckpt\n"
     ]
    }
   ],
   "source": [
    "task = 1\n",
    "logger = NanoDetLightningLogger('run_logs/task'+str(task))\n",
    "logger.info(\"Starting task\" + str(task))\n",
    "logger.info(\"Setting up data...\")\n",
    "#Create the task configuration file based on the task number and load the configuration\n",
    "create_exp_cfg('cfg/VOC_dist.yml', task)\n",
    "load_config(cfg, 'cfg/task' + str(task) + '.yml')\n",
    "#Build datasets and dataloaders based on the task configuration file\n",
    "train_dataset = build_dataset(cfg.data.train, \"train\")\n",
    "#If task is not 0, create the replay dataset using the buffer\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=cfg.device.workers_per_gpu,\n",
    "    pin_memory=True,\n",
    "    collate_fn=naive_collate,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_dataset = build_dataset(cfg.data.val, \"test\")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=cfg.device.batchsize_per_gpu,\n",
    "    shuffle=False,\n",
    "    num_workers=cfg.device.workers_per_gpu,\n",
    "    pin_memory=True,\n",
    "    collate_fn=naive_collate,\n",
    "    drop_last=False,\n",
    ")\n",
    "evaluator = build_evaluator(cfg.evaluator, val_dataset)\n",
    "\n",
    "#Create the model based on the task configuration file\n",
    "logger.info(\"Creating models\")\n",
    "if task == 0:\n",
    "    TrainTask = TrainingTask(cfg, evaluator)\n",
    "else:\n",
    "    TrainTask = LatentDistTrainingTask(cfg, evaluator)\n",
    "    #Load the model weights if task is not 0\n",
    "    if \"load_model\" in cfg.schedule:\n",
    "        ckpt = torch.load(cfg.schedule.load_model)\n",
    "        load_model_weight(TrainTask.model, ckpt, logger)\n",
    "        load_model_weight(TrainTask.teacher, ckpt, logger)\n",
    "        logger.info(\"Loaded model weight from {}\".format(cfg.schedule.load_model))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T14:03:18.555621020Z",
     "start_time": "2024-02-20T14:03:17.498115902Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for batch in train_dataloader:\n",
    "    batch = TrainTask._preprocess_batch_input(batch)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T14:03:26.493843041Z",
     "start_time": "2024-02-20T14:03:26.042131Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 116, 28, 40])\n",
      "torch.Size([1, 232, 14, 20])\n",
      "torch.Size([1, 464, 7, 10])\n"
     ]
    }
   ],
   "source": [
    "img = batch[\"img\"]\n",
    "feat = TrainTask.model.backbone(img)\n",
    "for tensor in feat:\n",
    "    print(tensor.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T14:04:25.076503332Z",
     "start_time": "2024-02-20T14:04:25.044243763Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 116, 28, 40])\n",
      "torch.Size([1, 232, 14, 20])\n",
      "torch.Size([1, 464, 7, 10])\n"
     ]
    }
   ],
   "source": [
    "img = batch[\"img\"]\n",
    "feat = TrainTask.teacher.backbone(img)\n",
    "for tensor in feat:\n",
    "    print(tensor.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T14:07:19.588230469Z",
     "start_time": "2024-02-20T14:07:19.547730253Z"
    }
   },
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "feat = TrainTask.model.backbone(img)\n",
    "print(feat)\n",
    "stud_fpn_feat = TrainTask.model.fpn(stud_feat)\n",
    "teach_int_head_out = []\n",
    "for feat, cls_convs in zip(stud_fpn_feat, TrainTask.model.head.cls_convs):\n",
    "    for conv in cls_convs:\n",
    "        feat = conv(feat)\n",
    "    teach_int_head_out.append(feat)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T09:15:30.402404832Z",
     "start_time": "2024-02-19T09:15:30.340791233Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 16, 20])\n"
     ]
    }
   ],
   "source": [
    "print(teach_int_head_out[1].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T09:16:28.939355086Z",
     "start_time": "2024-02-19T09:16:28.911482590Z"
    }
   },
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 116, 32, 40])\n",
      "torch.Size([1, 116, 32, 40])\n",
      "torch.Size([1, 232, 16, 20])\n",
      "torch.Size([1, 232, 16, 20])\n",
      "torch.Size([1, 464, 8, 10])\n",
      "torch.Size([1, 464, 8, 10])\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "stud_feat = TrainTask.model.backbone(img)\n",
    "lista = []\n",
    "lista1 = []\n",
    "for tensor in stud_feat:\n",
    "    tensor_prob = nn.functional.softmax(tensor, dim=1)\n",
    "    lista.append(tensor)\n",
    "    lista1.append(tensor_prob)\n",
    "    print(tensor_prob.shape)\n",
    "    print(tensor.shape)\n",
    "mse_loss = nn.MSELoss()\n",
    "for tensor1, tensor2 in zip(stud_feat,stud_feat):\n",
    "    loss = mse_loss(tensor1, tensor2)\n",
    "    print(loss)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T08:59:42.860739876Z",
     "start_time": "2024-02-19T08:59:42.784029288Z"
    }
   },
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\n    output = gfl_cls(feat)\\n    outputs.append(output.flatten(start_dim=2))\\noutputs = torch.cat(outputs, dim=2).permute(0, 2, 1)\\n'"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "outputs = []\n",
    "for feat, cls_convs in zip(\n",
    "    stud_fpn_feat,\n",
    "    TrainTask.model.head.cls_convs,\n",
    "):\n",
    "    for conv in cls_convs:\n",
    "        feat = conv(feat)\n",
    "    outputs.append(feat)\n",
    "    \n",
    "\n",
    "mse_list = []\n",
    "for tensor1, tensor2 in zip(outputs,outputs):\n",
    "    mse = F.mse_loss(tensor1, tensor2)\n",
    "    mse_list.append(mse.item())   \n",
    "print(mse_list)\n",
    "'''\n",
    "    output = gfl_cls(feat)\n",
    "    outputs.append(output.flatten(start_dim=2))\n",
    "outputs = torch.cat(outputs, dim=2).permute(0, 2, 1)\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T13:49:46.440965312Z",
     "start_time": "2024-02-15T13:49:46.425614135Z"
    }
   },
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DepthwiseConvModule(\n",
      "  (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "  (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "teacher_state_dict = TrainTask.teacher.head.state_dict()\n",
    "student_state_dict = TrainTask.model.head.state_dict()\n",
    "print(TrainTask.teacher.head.cls_convs[0][1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T11:56:11.434892746Z",
     "start_time": "2024-02-15T11:56:11.356309101Z"
    }
   },
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "head = TrainTask.teacher.head"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T12:01:51.929766699Z",
     "start_time": "2024-02-15T12:01:51.888824451Z"
    }
   },
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): DepthwiseConvModule(\n",
      "    (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "    (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (1): DepthwiseConvModule(\n",
      "    (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "    (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      ")\n",
      "ModuleList(\n",
      "  (0): DepthwiseConvModule(\n",
      "    (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "    (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (1): DepthwiseConvModule(\n",
      "    (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "    (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      ")\n",
      "ModuleList(\n",
      "  (0): DepthwiseConvModule(\n",
      "    (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "    (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (1): DepthwiseConvModule(\n",
      "    (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "    (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      ")\n",
      "ModuleList(\n",
      "  (0): DepthwiseConvModule(\n",
      "    (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "    (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      "  (1): DepthwiseConvModule(\n",
      "    (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
      "    (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for conv in head.cls_convs:\n",
    "    print(conv)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T12:02:07.965283148Z",
     "start_time": "2024-02-15T12:02:07.910537954Z"
    }
   },
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "##################\n",
    "# COPY HEAD TEST #\n",
    "##################\n",
    "# Get the state dict of both models\n",
    "teacher_state_dict = TrainTask.teacher.head.gfl_cls.state_dict()\n",
    "student_state_dict = TrainTask.model.head.gfl_cls.state_dict()\n",
    "# Update the specific layer weights in the student model with the teacher model weights\n",
    "for name, param in teacher_state_dict.items():\n",
    "    # Slice the weights tensor along the out_channels dimension from 0 to 15\n",
    "    student_state_dict[name][:17] = param[:17]\n",
    "# Load the updated state dict into the student model\n",
    "TrainTask.model.head.gfl_cls.load_state_dict(student_state_dict)\n",
    "trainer.save_checkpoint(\"models/task1/model_last.ckpt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T11:42:13.655651932Z",
     "start_time": "2024-02-15T11:42:13.631978953Z"
    }
   },
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanodet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
